# Distillation experiments
The goal of this repository is to train a classifier model and expose it to adversarial samples. A distilled version of the model will then be created augmenting the latter to defend against adversarial perturbations following the work of [(Papernot et al., 2016)](https://arxiv.org/abs/1511.04508).

Notes: Crafting Adverserial samples [(Goodfellow et al., 2014)](https://arxiv.org/pdf/1412.6572)
